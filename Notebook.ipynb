{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMS to CONVERSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://aws-athena-query-results-101063123548-eu-west-1/Unsaved/2020/05/07/8a853c10-ffcf-4f58-b83c-2e2513a5e51e.csv to s3://datateam-ml/CVR_FSI/sms.csv\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://aws-athena-query-results-101063123548-eu-west-1/Unsaved/2020/05/07/8a853c10-ffcf-4f58-b83c-2e2513a5e51e.csv s3://datateam-ml/CVR_FSI/sms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"s3://datateam-ml/CVR_FSI/conversions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"s3://datateam-ml/CVR_FSI/sms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = yaml.safe_load(open(\"Attributes_yaml/features.yml\"))\n",
    "input_col = features['input_col']+features['target']\n",
    "data = data[input_col]\n",
    "data = data.reindex(columns = input_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING OF THE PRE-PROCESSING PIPELINE AND MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy as sci\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/FSI_SMS_TO_CONVERSION\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processing():\n",
    "    \n",
    "    features = yaml.safe_load(open(\"Attributes_yaml/features.yml\"))\n",
    "    input_col = features['input_col']\n",
    "    num = features['num_features']\n",
    "    cat = features['cat_features']\n",
    "    target = features['target']\n",
    "    low_cat = features['low_cat']\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def map_values(self,column = 'event_type'):\n",
    "        self.data['event_type'] = self.data['event_type'].apply(lambda x: 1 if x == 'install' else 0)\n",
    "#     def map_values(self):\n",
    "#         self.dictionary = {'sms': 0, 'install':1}\n",
    "#         self.data[processing.target] = self.data[processing.target].index.map(self.dictionary.get)\n",
    "#         #self.data[processing.target] = self.data[processing.target].index.apply(lambda x: 1 if x == 'install' else 0)\n",
    "    def fill_na(self):\n",
    "        for item in self.data[processing.num]:\n",
    "            self.data[item] = self.data[item].fillna(self.data[item].mean())\n",
    "        for item in self.data[processing.cat]:\n",
    "            self.data[item] = self.data[item].fillna(self.data[item].value_counts().index[0])\n",
    "    def hash_list(self):\n",
    "        self.hash_features = []\n",
    "        for item in processing.cat:\n",
    "            if item not in processing.low_cat:\n",
    "                self.hash_features.append(item)\n",
    "    def pipeline(self, hash_size):\n",
    "        self.num_pipeline = Pipeline(steps= [('imputer', SimpleImputer(strategy='mean')), ('std_scaler', MinMaxScaler())])\n",
    "        self.cat_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "                                       ('one_hot_encoding', OneHotEncoder(handle_unknown = \"ignore\", sparse = False))])\n",
    "        self.hash_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "                                  ('hasher', FeatureHasher(n_features=hash_size, input_type='string'))])\n",
    "        \n",
    "    \n",
    "    def build_pipe(self, hash_size = 500, test_size = 0.2): \n",
    "        self.fill_na()\n",
    "        self.map_values()\n",
    "        self.data.drop(['msisdn'],axis=1,inplace=True)\n",
    "        self.hash_list()\n",
    "        self.pipeline(hash_size)\n",
    "        \n",
    "        self.full_pipeline = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', self.num_pipeline, processing.num),\n",
    "            ('cat', self.cat_pipeline, processing.low_cat),\n",
    "            ('hash', self.hash_pipeline, self.hash_features)\n",
    "        ])\n",
    "        \n",
    "        self.X = self.data.drop(processing.target, axis=1)\n",
    "        self.y = self.data[processing.target].copy()\n",
    "        \n",
    "        self.full_pipeline.fit(self.X)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size, stratify = self.y)\n",
    "        \n",
    "        self.X_train = self.full_pipeline.transform(self.X_train)\n",
    "        self.X_test = self.full_pipeline.transform(self.X_test)\n",
    "        \n",
    "        print(self.X_train.shape)\n",
    "        return self.X, self.y, self.X_train, self.X_test, self.y_train, self.y_test, self.full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212245, 517)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_train, X_test, y_train, y_test, full_pipeline = processed.build_pipe(hash_size = 500, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING (LINEAR + DEEP MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "               KNeighborsClassifier(3),\n",
    "               DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(),\n",
    "               AdaBoostClassifier(),\n",
    "               GradientBoostingClassifier(),\n",
    "               LogisticRegression(C=1,random_state=1234,solver = 'lbfgs',class_weight={0:0.1, 1:0.90})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "model score: 0.939\n",
      "confusion matrix\n",
      "[[49134   897]\n",
      " [ 2363   668]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     50031\n",
      "           1       0.43      0.22      0.29      3031\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     53062\n",
      "   macro avg       0.69      0.60      0.63     53062\n",
      "weighted avg       0.92      0.94      0.93     53062\n",
      "\n",
      "Accuracy : 0.938562\n",
      "f1 score : 0.359488\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "model score: 0.957\n",
      "confusion matrix\n",
      "[[49058   973]\n",
      " [ 1305  1726]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     50031\n",
      "           1       0.64      0.57      0.60      3031\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     53062\n",
      "   macro avg       0.81      0.78      0.79     53062\n",
      "weighted avg       0.95      0.96      0.96     53062\n",
      "\n",
      "Accuracy : 0.957069\n",
      "f1 score : 0.624141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "model score: 0.965\n",
      "confusion matrix\n",
      "[[49941    90]\n",
      " [ 1772  1259]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     50031\n",
      "           1       0.93      0.42      0.57      3031\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     53062\n",
      "   macro avg       0.95      0.71      0.78     53062\n",
      "weighted avg       0.96      0.96      0.96     53062\n",
      "\n",
      "Accuracy : 0.964909\n",
      "f1 score : 0.747004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "model score: 0.942\n",
      "confusion matrix\n",
      "[[49881   150]\n",
      " [ 2940    91]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     50031\n",
      "           1       0.38      0.03      0.06      3031\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     53062\n",
      "   macro avg       0.66      0.51      0.51     53062\n",
      "weighted avg       0.91      0.94      0.92     53062\n",
      "\n",
      "Accuracy : 0.941766\n",
      "f1 score : 0.113892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "model score: 0.943\n",
      "confusion matrix\n",
      "[[49993    38]\n",
      " [ 2969    62]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     50031\n",
      "           1       0.62      0.02      0.04      3031\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     53062\n",
      "   macro avg       0.78      0.51      0.51     53062\n",
      "weighted avg       0.93      0.94      0.92     53062\n",
      "\n",
      "Accuracy : 0.943330\n",
      "f1 score : 0.090353\n",
      "LogisticRegression(C=1, class_weight={0: 0.1, 1: 0.9}, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=1234,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
      "model score: 0.829\n",
      "confusion matrix\n",
      "[[42168  7863]\n",
      " [ 1229  1802]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90     50031\n",
      "           1       0.19      0.59      0.28      3031\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     53062\n",
      "   macro avg       0.58      0.72      0.59     53062\n",
      "weighted avg       0.93      0.83      0.87     53062\n",
      "\n",
      "Accuracy : 0.828653\n",
      "f1 score : 0.216114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % classifier.score(X_test, y_test))\n",
    "    print('confusion matrix')\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print('classification report')\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('f1 score : %f' % (metrics.fbeta_score(y_test, y_pred, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(256,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "model score: 0.942\n",
      "confusion matrix\n",
      "[[49898   133]\n",
      " [ 2929   102]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     50031\n",
      "           1       0.43      0.03      0.06      3031\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     53062\n",
      "   macro avg       0.69      0.52      0.52     53062\n",
      "weighted avg       0.92      0.94      0.92     53062\n",
      "\n",
      "Accuracy : 0.942294\n",
      "f1 score : 0.128431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier #implements a multi-layer perceptron (MLP) algorithm\n",
    "MLP = MLPClassifier(solver='lbfgs', alpha=0.001,\n",
    "                          hidden_layer_sizes=(256,), random_state=1)\n",
    "MLP.fit(X_train, y_train)\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(MLP)\n",
    "print(\"model score: %.3f\" % MLP.score(X_test, y_test))\n",
    "print('confusion matrix')\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print('classification report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('f1 score : %f' % (metrics.fbeta_score(y_test, y_pred, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '/home/ec2-user/SageMaker/FSI_SMS_TO_CONVERSION/model_and_pipeline/model_KNN.pkl'\n",
    "pickle.dump(KNN, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
